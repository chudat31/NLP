{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist, LidstoneProbDist\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "import time\n",
    "\n",
    "# Đọc dữ liệu từ file\n",
    "with open('student_feedback_dataset.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo tri-gram từ dữ liệu\n",
    "def create_ngram_model(data, n=3):\n",
    "    n_grams = ngrams(data, n, pad_left=True, pad_right=True)\n",
    "    freq_dist = FreqDist(n_grams)\n",
    "    return freq_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tính xác suất của một câu sử dụng tri-gram model và add-one smoothing\n",
    "def calculate_sentence_probability(sentence, ngram_model):\n",
    "    sentence_ngrams = list(ngrams(sentence, 3, pad_left=True, pad_right=True))\n",
    "    probability = 1.0\n",
    "\n",
    "    for ngram in sentence_ngrams:\n",
    "        count_ngram = ngram_model[ngram]\n",
    "        count_n_1gram = ngram_model[ngram[:2]]\n",
    "        probability *= (count_ngram + 1) / (count_n_1gram + len(ngram_model))\n",
    "\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng model từ dữ liệu\n",
    "ngram_model = create_ngram_model(nltk.word_tokenize(' '.join(data)))\n",
    "\n",
    "# Hàm đánh giá câu và đo thời gian thực hiện\n",
    "def evaluate_sentence(sentence):\n",
    "    start_time = time.time()\n",
    "    probability = calculate_sentence_probability(nltk.word_tokenize(sentence), ngram_model)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    return probability, execution_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xác suất của câu 'cần tạo các buổi seminar để sinh viên có thể hiểu sâu thêm về các vấn đề trong chuyên ngành nhưng không có trong môn học .' là: 9.610126978660555e-121\n",
      "Thời gian thực hiện: 0.001036 giây\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Gọi hàm để đánh giá câu và in ra kết quả\n",
    "input_sentence = input(\"Nhập câu cần đánh giá: \")\n",
    "probability, execution_time = evaluate_sentence(input_sentence)\n",
    "print(\"Xác suất của câu '{}' là: {}\".format(input_sentence, probability))\n",
    "print(\"Thời gian thực hiện: {:.6f} giây\".format(execution_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fd4c668060f90bcaef0abab70a9153057495c494049760458fb42d2a47428be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
